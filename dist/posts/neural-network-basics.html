<article class="max-w-4xl mx-auto space-y-8">
    <!-- 文章头部 -->
    <header class="space-y-6">
        <div class="flex items-center space-x-4 text-sm text-slate-400">
            <span>2024年1月15日</span>
            <span>•</span>
            <span>8分钟阅读</span>
            <span>•</span>
            <span>深度学习</span>
        </div>
        
        <h1 class="text-4xl md:text-5xl font-bold bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent">
            神经网络基础：从零开始理解深度学习
        </h1>
        
        <p class="text-xl text-slate-300 leading-relaxed">
            深入探讨神经网络的基本概念，包括前向传播、反向传播和梯度下降等核心算法，为理解现代深度学习奠定基础。
        </p>
        
        <div class="flex flex-wrap gap-2">
            <span class="px-3 py-1 bg-blue-500/20 text-blue-300 rounded-full text-xs">深度学习</span>
            <span class="px-3 py-1 bg-purple-500/20 text-purple-300 rounded-full text-xs">神经网络</span>
            <span class="px-3 py-1 bg-green-500/20 text-green-300 rounded-full text-xs">机器学习</span>
        </div>
    </header>

    <!-- 文章内容 -->
    <div class="prose prose-invert prose-lg max-w-none">
        <h2>引言</h2>
        <p>
            神经网络是深度学习的核心，它模拟了人脑神经元的工作方式。本文将带你从零开始理解神经网络的基本概念和工作原理。
        </p>

        <h2>什么是神经网络？</h2>
        <p>
            神经网络是一种模仿生物神经系统的计算模型，由大量相互连接的神经元组成。每个神经元接收输入，进行加权求和，然后通过激活函数产生输出。
        </p>

        <div class="bg-slate-800/30 rounded-xl p-6 border border-slate-700/50 my-6">
            <h3 class="text-lg font-semibold text-white mb-4">关键概念</h3>
            <ul class="space-y-2 text-slate-300">
                <li><strong>神经元（Neuron）：</strong>神经网络的基本计算单元</li>
                <li><strong>权重（Weight）：</strong>连接强度，决定输入的重要性</li>
                <li><strong>偏置（Bias）：</strong>调整神经元激活的阈值</li>
                <li><strong>激活函数（Activation Function）：</strong>引入非线性变换</li>
            </ul>
        </div>

        <h2>前向传播</h2>
        <p>
            前向传播是神经网络的核心计算过程。输入数据从输入层开始，逐层向前传播，最终在输出层得到预测结果。
        </p>

        <h3>数学表示</h3>
        <p>
            对于第l层的第j个神经元，其输出可以表示为：
        </p>
        
        <div class="bg-slate-800/30 rounded-lg p-4 my-4 overflow-x-auto">
            <code class="text-green-400">
                z_j^(l) = Σ(w_ij^(l) * a_i^(l-1)) + b_j^(l)<br>
                a_j^(l) = f(z_j^(l))
            </code>
        </div>

        <p>
            其中：
        </p>
        <ul>
            <li>z_j^(l) 是第l层第j个神经元的加权输入</li>
            <li>w_ij^(l) 是连接权重</li>
            <li>a_i^(l-1) 是上一层的输出</li>
            <li>b_j^(l) 是偏置项</li>
            <li>f(·) 是激活函数</li>
        </ul>

        <h2>反向传播</h2>
        <p>
            反向传播算法用于计算损失函数对网络参数的梯度，是训练神经网络的关键算法。
        </p>

        <div class="bg-blue-500/10 border border-blue-500/20 rounded-xl p-6 my-6">
            <h3 class="text-lg font-semibold text-blue-300 mb-4">💡 重要提示</h3>
            <p class="text-slate-300">
                反向传播的核心思想是链式法则。通过计算损失函数对每个参数的偏导数，我们可以知道如何调整参数来减少损失。
            </p>
        </div>

        <h2>梯度下降</h2>
        <p>
            梯度下降是最常用的优化算法，通过沿着梯度的反方向更新参数来最小化损失函数。
        </p>

        <h3>参数更新规则</h3>
        <div class="bg-slate-800/30 rounded-lg p-4 my-4 overflow-x-auto">
            <code class="text-green-400">
                w = w - α * ∂L/∂w<br>
                b = b - α * ∂L/∂b
            </code>
        </div>

        <p>
            其中α是学习率，控制参数更新的步长。
        </p>

        <h2>常见的激活函数</h2>
        
        <div class="grid md:grid-cols-2 gap-6 my-6">
            <div class="bg-slate-800/30 rounded-xl p-6 border border-slate-700/50">
                <h4 class="font-semibold text-white mb-3">ReLU (Rectified Linear Unit)</h4>
                <p class="text-slate-300 text-sm mb-3">f(x) = max(0, x)</p>
                <div class="bg-slate-700/50 rounded p-2">
                    <code class="text-green-400 text-xs">优点：计算简单，缓解梯度消失</code>
                </div>
            </div>
            
            <div class="bg-slate-800/30 rounded-xl p-6 border border-slate-700/50">
                <h4 class="font-semibold text-white mb-3">Sigmoid</h4>
                <p class="text-slate-300 text-sm mb-3">f(x) = 1 / (1 + e^(-x))</p>
                <div class="bg-slate-700/50 rounded p-2">
                    <code class="text-green-400 text-xs">优点：输出范围[0,1]，适合二分类</code>
                </div>
            </div>
        </div>

        <h2>实践建议</h2>
        <ol>
            <li><strong>数据预处理：</strong>标准化输入数据，确保特征在相似范围内</li>
            <li><strong>权重初始化：</strong>使用合适的初始化方法，如Xavier或He初始化</li>
            <li><strong>学习率选择：</strong>从较小的学习率开始，根据训练情况调整</li>
            <li><strong>正则化：</strong>使用Dropout、L1/L2正则化防止过拟合</li>
        </ol>

        <div class="bg-yellow-500/10 border border-yellow-500/20 rounded-xl p-6 my-6">
            <h3 class="text-lg font-semibold text-yellow-300 mb-4">⚠️ 注意事项</h3>
            <ul class="space-y-2 text-slate-300">
                <li>梯度消失和梯度爆炸是训练深层网络时的常见问题</li>
                <li>过拟合是机器学习中的主要挑战之一</li>
                <li>选择合适的网络架构对性能至关重要</li>
            </ul>
        </div>

        <h2>总结</h2>
        <p>
            神经网络是现代深度学习的基石。理解前向传播、反向传播和梯度下降这些基本概念，是掌握深度学习的关键第一步。
            在后续的文章中，我们将深入探讨更高级的主题，如卷积神经网络、循环神经网络等。
        </p>
    </div>

    <!-- 文章底部 -->
    <footer class="border-t border-slate-700/50 pt-8 mt-12">
        <div class="flex flex-col md:flex-row md:items-center md:justify-between space-y-4 md:space-y-0">
            <div class="flex items-center space-x-4">
                <span class="text-slate-400">分享到：</span>
                <a href="#" class="text-slate-400 hover:text-blue-400 transition-colors">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                        <path d="M24 4.557c-.883.392-1.832.656-2.828.775 1.017-.609 1.798-1.574 2.165-2.724-.951.564-2.005.974-3.127 1.195-.897-.957-2.178-1.555-3.594-1.555-3.179 0-5.515 2.966-4.797 6.045-4.091-.205-7.719-2.165-10.148-5.144-1.29 2.213-.669 5.108 1.523 6.574-.806-.026-1.566-.247-2.229-.616-.054 2.281 1.581 4.415 3.949 4.89-.693.188-1.452.232-2.224.084.626 1.956 2.444 3.379 4.6 3.419-2.07 1.623-4.678 2.348-7.29 2.04 2.179 1.397 4.768 2.212 7.548 2.212 9.142 0 14.307-7.721 13.995-14.646.962-.695 1.797-1.562 2.457-2.549z"/>
                    </svg>
                </a>
                <a href="#" class="text-slate-400 hover:text-blue-400 transition-colors">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                        <path d="M22.46 6c-.77.35-1.6.58-2.46.69.88-.53 1.56-1.37 1.88-2.38-.83.5-1.75.85-2.72 1.05C18.37 4.5 17.26 4 16 4c-2.35 0-4.27 1.92-4.27 4.29 0 .34.04.67.11.98C8.28 9.09 5.11 7.38 3 4.79c-.37.63-.58 1.37-.58 2.15 0 1.49.75 2.81 1.91 3.56-.71 0-1.37-.2-1.95-.5v.03c0 2.08 1.48 3.82 3.44 4.21a4.22 4.22 0 0 1-1.93.07 4.28 4.28 0 0 0 4 2.98 8.521 8.521 0 0 1-5.33 1.84c-.34 0-.68-.02-1.02-.06C3.44 20.29 5.7 21 8.12 21 16 21 20.33 14.46 20.33 8.79c0-.19 0-.37-.01-.56.84-.6 1.56-1.36 2.14-2.23z"/>
                    </svg>
                </a>
            </div>
            
            <div class="flex items-center space-x-4">
                <a href="/posts/multimodal-ai" class="text-blue-400 hover:text-blue-300 transition-colors text-sm">
                    下一篇：多模态AI →
                </a>
            </div>
        </div>
    </footer>
</article> 